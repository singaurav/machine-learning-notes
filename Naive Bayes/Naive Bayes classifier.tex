\documentclass[11pt, a4paper]{article}


\usepackage{amsmath}
\usepackage{booktabs}

\begin{document}

\title{NAIVE BAYES CLASSIFIER}
\date{}
\maketitle

Supervised learning algorithm based on the application of Bayes\textsc{\char13} theorem with the 
``naive'' assumption of independence between every pair of features.

\section{Bayes' Theorem}

\begin{align*}
	\mathbf{P}(A\cap B) = \mathbf{P}(A|B) \times \mathbf{P}(B)                   \\
	= \mathbf{P}(B|A) \times \mathbf{P}(A)                                       \\
	                                                                             \\
	\mathbf{P}(A|B) = \frac{\mathbf{P}(B|A) \times \mathbf{P}(A)}{\mathbf{P}(B)} 
\end{align*}

\section{Derivation}

\begin{align*}
	\mathbf{P}(\mathbf{Y}=y_k\ |\ x_1,\ x_2,\ ...\ x_p) = \frac{\mathbf{P}(x_1,\ x_2,\ ...\ x_p|\mathbf{Y}=y_k) \times \mathbf{P}(\mathbf{Y}=y_k)}{\mathbf{P}(x_1,\ x_2,\ ...\ x_p)} \\
\end{align*}

Choose $y_k$ which maximizes $\mathbf{P}(\mathbf{Y}=y_k | x_1,\ x_2,\ ...\ x_p)$. 

\begin{align*}
	\mathbf{Y} = \operatorname*{argmax}_{y_k}\left\{                                                                             
	\begin{array}{ll}                                                                                                            
	\frac{\mathbf{P}(x_1,\ x_2,\ ...\ x_p | \mathbf{Y}=y_k) \times \mathbf{P}(\mathbf{Y=y_k)}}{\mathbf{P}(x_1,\ x_2,\ ...\ x_p)} \\
	\end{array}                                                                                                                  
	\right.                                                                                                                      \\
\end{align*}

Since $\mathbf{P}(x_1,\ x_2,\ ...\ x_p)$ is constant for all $y_k$, the above can be written as follows: 

\begin{align*}
	\mathbf{Y} = \operatorname*{argmax}_{y_k}\left\{                                    
	\begin{array}{ll}                                                                   
	\mathbf{P}(x_1,\ x_2,\ ...\ x_p | \mathbf{Y}=y_k) \times \mathbf{P}(\mathbf{Y=y_k)} \\
	\end{array}                                                                         
	\right.                                                                             \\
\end{align*}

The ``naive'' assumption that all $\mathbf{X_1},\ \mathbf{X_2},\ ...\ \mathbf{X_p}$ are independent allows for the following simplification.

\begin{align*}
	\mathbf{Y} = \operatorname*{argmax}_{y_k}\left\{                           
	\begin{array}{ll}                                                          
	\prod_{i} \mathbf{P}(x_i|\mathbf{Y}=y_k) \times \mathbf{P}(\mathbf{Y=y_k)} \\
	\end{array}                                                                
	\right.                                                                    \\
\end{align*}

All the terms on the right are easy to calculate.

\section{Example}

\begin{table}[h!]
	\centering
	\caption{Training data}
	\label{tab:table1}
	\begin{tabular}{c|cccc|c}
		\toprule
		\textbf{Sr.} & \textbf{Outlook} & \textbf{Temperature} & \textbf{Humidity} & \textbf{Windy} & \textbf{PlayGolf} \\
		\midrule
		1            & Rainy            & Hot                  & High              & False          & No                \\
		2            & Rainy            & Hot                  & High              & True           & No                \\
		3            & Overcast         & Hot                  & High              & False          & Yes               \\
		4            & Sunny            & Mild                 & High              & False          & Yes               \\
		5            & Sunny            & Cool                 & Normal            & False          & Yes               \\
		6            & Sunny            & Cool                 & Normal            & True           & No                \\
		7            & Overcast         & Cool                 & Normal            & True           & Yes               \\
		8            & Rainy            & Mild                 & High              & False          & No                \\
		9            & Rainy            & Cool                 & Normal            & False          & Yes               \\
		10           & Sunny            & Mild                 & Normal            & False          & Yes               \\
		11           & Rainy            & Mild                 & Normal            & True           & Yes               \\
		12           & Overcast         & Mild                 & High              & True           & Yes               \\
		13           & Overcast         & Hot                  & Normal            & False          & Yes               \\
		14           & Sunny            & Mild                 & High              & True           & No                \\
		\bottomrule
	\end{tabular}
\end{table}

\noindent The following tables are calculated.

\begin{table}[h!]
	\centering
	\label{tab:table2}
	\begin{tabular}{c|cc}
		\toprule
		\textbf{Outlook} & \textbf{Yes} & \textbf{No} \\
		\midrule
		Rainy            & 2            & 3           \\
		Overcast         & 4            & 0           \\
		Sunny            & 3            & 2           \\
	\end{tabular}
	\hspace{2em}
	\vspace{2em}
	\label{tab:table3}
	\begin{tabular}{c|cc}
		\toprule
		\textbf{Temperature} & \textbf{Yes} & \textbf{No} \\
		\midrule
		Hot                  & 2            & 2           \\
		Mild                 & 4            & 2           \\
		Cool                 & 3            & 1           \\
	\end{tabular}
	\label{tab:table4}
	\begin{tabular}{c|cc}
		\toprule
		\textbf{Humidity} & \textbf{Yes} & \textbf{No} \\
		\midrule
		High              & 3            & 4           \\
		Normal            & 6            & 1           \\
	\end{tabular}
	\hspace{2em}
	\label{tab:table5}
	\begin{tabular}{c|cc}
		\toprule
		\textbf{Windy} & \textbf{Yes} & \textbf{No} \\
		\midrule
		False          & 6            & 2           \\
		True           & 3            & 3           \\
	\end{tabular}
\end{table}

If $X = (Sunny, Hot, Normal, False)$, then 

\begin{align*}
	\mathbf{PlayGolf} = \operatorname*{argmax}_{y_k}\left\{          
	\begin{array}{ll}                                                
	\mathbf{P}(\textbf{Outlook}=Sunny|\textbf{PlayGolf}=Yes)         \\
	\times\mathbf{P}(\textbf{Temprature}=Hot|\textbf{PlayGolf}=Yes)  \\
	\times\mathbf{P}(\textbf{Humidity}=Normal|\textbf{PlayGolf}=Yes) \\
	\times\mathbf{P}(\textbf{Windy}=False|\textbf{PlayGolf}=Yes)     \\
	\times\mathbf{P}(\textbf{PlayGolf}=Yes)                          \\
	                                                                 \\
	\mathbf{P}(\textbf{Outlook}=Sunny|\textbf{PlayGolf}=No)          \\
	\times\mathbf{P}(\textbf{Temprature}=Hot|\textbf{PlayGolf}=No)   \\
	\times\mathbf{P}(\textbf{Humidity}=Normal|\textbf{PlayGolf}=No)  \\
	\times\mathbf{P}(\textbf{Windy}=False|\textbf{PlayGolf}=No)      \\
	\times\mathbf{P}(\textbf{PlayGolf}=No)                           \\
	\end{array}                                                      
	\right.                                                          
\end{align*}

\begin{align*}
	\mathbf{PlayGolf} = \operatorname*{argmax}_{y_k}\left\{ 
	\begin{array}{ll}                                       
	3/9                                                     \\
	\times2/9                                               \\
	\times6/9                                               \\
	\times6/9                                               \\
	\times9/14                                              \\
	                                                        \\
	2/5                                                     \\
	\times2/5                                               \\
	\times1/5                                               \\
	\times2/5                                               \\
	\times5/14                                              \\
	\end{array}                                             
	\right.                                                 
\end{align*}

\begin{align*}
	\mathbf{PlayGolf} = \operatorname*{argmax}_{y_k}\left\{ 
	\begin{array}{ll}                                       
	0.0212                                                  
	                                                        \\
	0.0046                                                  \\
	\end{array}                                             
	\right.                                                 
\end{align*}

Therefore, $\textbf{PlayGolf}=Yes$ because $0.0212 > 0.0046$.

\section{Extensions} 

\begin{itemize}
	\item For a continuous input feature, assumption regarding the distribution needs to be made. Examples: \textbf{Gaussian}, \textbf{Multinomial} and \textbf{Bernoulli}. 
	\item Smoothing may be required to prevent the multiplication from being zero when one probability term is zero.
\end{itemize}

\section{Comments}
\begin{itemize}
	\item Due to independence assumption, naive Bayes' classifiers often perform good even with less training data.
	\item Main applications include \textbf{spam filtering} and \textbf{document classification}.
	\item Extremely fast in both training and prediction.
	\item Often fail to produce a good estimate of the correct class probabilities but make the correct classification if the correct class is more probable than any other class.
\end{itemize}
\end{document}